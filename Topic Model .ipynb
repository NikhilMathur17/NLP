{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected: C:/Users/Rohit/Downloads/reviews.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.041*\"citizenship\" + 0.023*\"india\" + 0.021*\"amendment\" + 0.021*\"protest\" + 0.021*\"student\"'), (1, '0.005*\"citizenship\" + 0.005*\"india\" + 0.005*\"student\" + 0.005*\"protest\" + 0.005*\"amendment\"')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  citizenship   india   amendment   protest   student \n",
      "A person who stays beyond the visa permit is also referred to as an illegal immigrant.When did the issue of Citizenship (Amendment) Bill come up?Prior to the 2014 Lok Sabha elections, the Bharatiya Janata Party (BJP), which was seeking to topple the Congress-led UPA government, promised to grant citizenship to Hindus persecuted in the neighbouring countries.\n",
      "  citizenship   india   amendment   protest   student \n",
      "['A person who stays beyond the visa permit is also referred to as an illegal immigrant.When did the issue of Citizenship (Amendment) Bill come up?Prior to the 2014 Lok Sabha elections, the Bharatiya Janata Party (BJP), which was seeking to topple the Congress-led UPA government, promised to grant citizenship to Hindus persecuted in the neighbouring countries.']\n",
      "Selected: C:/Users/Rohit/Downloads/acidattack.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.002*\"attack\" + 0.002*\"victim\" + 0.002*\"assault\" + 0.002*\"report\" + 0.002*\"social\"'), (1, '0.038*\"attack\" + 0.023*\"victim\" + 0.008*\"throw\" + 0.008*\"survivor\" + 0.008*\"assault\"')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "C:\\Users\\Rohit\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  attack   victim   assault   report   social \n",
      "Aqueous solutions of strongly alkaline materials, such as caustic soda (sodium hydroxide), are used as well, particularly in areas where strong acids are controlled substances.The long term consequences of these attacks may include blindness, as well as eye burns, with severe permanent scarring of the face and body,along with far-reaching social, psychological, and economic difficulties.Today, acid attacks are reported in many parts of the world, though more commonly in developing countries.\n",
      "  attack   victim   assault   report   social \n",
      "  attack   victim   assault   report   social \n",
      "['Aqueous solutions of strongly alkaline materials, such as caustic soda (sodium hydroxide), are used as well, particularly in areas where strong acids are controlled substances.The long term consequences of these attacks may include blindness, as well as eye burns, with severe permanent scarring of the face and body,along with far-reaching social, psychological, and economic difficulties.Today, acid attacks are reported in many parts of the world, though more commonly in developing countries.', '']\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog \n",
    "import tkinter.messagebox as tm\n",
    "from tkinter import *\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from spacy.lang.en import English\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.summarization import summarize\n",
    "from gensim.summarization import keywords\n",
    "from gensim import corpora\n",
    "import pickle\n",
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "import re\n",
    "\n",
    "datafile=\"\"\n",
    "topicfile=\"\"\n",
    "\n",
    "\n",
    "def UploadAction(event=None):\n",
    "    global datafile\n",
    "    global topicfile\n",
    "    filename = filedialog.askopenfilename()\n",
    "    print('Selected:', filename)\n",
    "    \n",
    "    parser = English()\n",
    "    def tokenize(text):\n",
    "        lda_tokens = []\n",
    "        tokens = parser(text)\n",
    "        for token in tokens:\n",
    "            if token.orth_.isspace():\n",
    "                continue\n",
    "            elif token.like_url:\n",
    "                lda_tokens.append('URL')\n",
    "            elif token.orth_.startswith('@'):\n",
    "                lda_tokens.append('SCREEN_NAME')\n",
    "            else:\n",
    "                lda_tokens.append(token.lower_)\n",
    "        return lda_tokens\n",
    "\n",
    "\n",
    "    def get_lemma(word):\n",
    "        lemma = wn.morphy(word)\n",
    "        if lemma is None:\n",
    "            return word\n",
    "        else:\n",
    "            return lemma\n",
    "    \n",
    "\n",
    "    def get_lemma2(word):\n",
    "        return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "    en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "\n",
    "    def prepare_text_for_lda(text):\n",
    "        tokens = tokenize(text)\n",
    "        tokens = [token for token in tokens if len(token) > 4]\n",
    "        tokens = [token for token in tokens if token not in en_stop]\n",
    "        tokens = [get_lemma(token) for token in tokens]\n",
    "        return tokens\n",
    "\n",
    "    \n",
    "    text_data = []\n",
    "    summ=[]\n",
    "    with open(filename, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            summ.append(summarize(line,ratio=0.05))\n",
    "            tokens = prepare_text_for_lda(line)\n",
    "            if True:\n",
    "                #print(tokens)\n",
    "                text_data.append(tokens)\n",
    "    datafile=summ         \n",
    "    dictionary = corpora.Dictionary(text_data)\n",
    "    corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "    pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "    dictionary.save('dictionary.gensim')\n",
    "    \n",
    "\n",
    "    NUM_TOPICS = 2\n",
    "    dictionary = gensim.corpora.Dictionary.load('dictionary.gensim')\n",
    "    corpus = pickle.load(open('corpus.pkl', 'rb'))\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "    ldamodel.save('model3.gensim')\n",
    "    topicfile = ldamodel.print_topics(num_words=5)\n",
    "    print(topicfile)\n",
    "\n",
    "    lda = gensim.models.ldamodel.LdaModel.load('model3.gensim')\n",
    "    \n",
    "    # Python3 code to demonstrate \n",
    "    # to extract words from string \n",
    "    # using regex( findall() ) \n",
    " \n",
    "\n",
    "    # initializing string \n",
    "    test_string = topicfile[0][1]\n",
    "\n",
    "    # printing original string \n",
    "    #print (\"The original string is : \" + test_string) \n",
    "\n",
    "    # using regex( findall() ) \n",
    "    # to extract words from string \n",
    "    res = re.findall(r'\\w+', test_string) \n",
    "\n",
    "    # printing result \n",
    "    #print (\"The list of words is : \" + str(res)) \n",
    "\n",
    "    # Python program to Remove all \n",
    "    # digits from a list of string \n",
    "    from string import digits \n",
    "\n",
    "    def remove(listr): \n",
    "        listr = [''.join(x for x in i if x.isalpha()) for i in listr] \n",
    "        return listr\n",
    "\n",
    "    # Driver code \n",
    "\n",
    "    listr = res\n",
    "    v=remove(listr)\n",
    "    #print(v)\n",
    "\n",
    "    # Function to convert \n",
    "    def listToString(s): \n",
    "\n",
    "    # initialize an empty string \n",
    "        str1 = \"\" \n",
    "    \n",
    "    # traverse in the string \n",
    "        for ele in s: \n",
    "            str1 += ele+' ' \n",
    "        # return string \n",
    "        return str1 \n",
    "\n",
    "    # Driver code\t \n",
    "    s = v\n",
    "    topicfile=listToString(s) \n",
    "    print(topicfile)\n",
    "    \n",
    "    print(datafile[0])\n",
    "    #lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "    #pyLDAvis.display(lda_display)\n",
    "    \n",
    "def Display_function():\n",
    "    global topicfile\n",
    "    print(topicfile)\n",
    "    \n",
    "    textBox2.delete('1.0', END)\n",
    "    textBox2.insert(tk.END, topicfile)\n",
    "\n",
    "def Summary_function():\n",
    "    global datafile\n",
    "    print(datafile)\n",
    "    \n",
    "    textBox1.delete('1.0', END)\n",
    "    textBox1.insert(tk.END, datafile[0])\n",
    "\n",
    "window = tk.Tk()\n",
    "#window.geometry(\"200x200+30+30\")\n",
    "window.state('zoomed')\n",
    "window.title(\"Topic predictor\")\n",
    "button1 = tk.Button(window, text='Upload Text File', command=UploadAction)\n",
    "button2 = tk.Button(window, text='Topics', command=Display_function)\n",
    "button3 = tk.Button(window, text='Summarize', command=Summary_function)\n",
    "\n",
    "display = tk.Label(window)\n",
    "textBox2=Text(window, height=10, width=100)\n",
    "display.pack()\n",
    "o = tk.Label(window, text=\"5 Most Relevant Topics\")\n",
    "o.pack()\n",
    "o.place(x = 640, y = 40, width=120, height=50)\n",
    "\n",
    "display = tk.Label(window)\n",
    "textBox1=Text(window, height=15, width=100)\n",
    "display.pack()\n",
    "o = tk.Label(window, text=\"Summary of the topic\")\n",
    "o.pack()\n",
    "o.place(x = 640, y = 340, width=120, height=50)\n",
    "\n",
    "textBox2.pack()\n",
    "textBox2.place(x = 300, y = 90)\n",
    "textBox1.pack()\n",
    "textBox1.place(x = 300, y= 390) \n",
    "button1.pack()\n",
    "button1.place(x = 70, y = 100, width=120, height=50)\n",
    "button2.pack()\n",
    "button2.place(x = 640, y = 280, width=120, height=50)\n",
    "button3.pack()\n",
    "button3.place(x = 640, y = 650, width=120, height=50)\n",
    "   \n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
